import streamlit as st
import pandas as pd
import tempfile, logging
import os
# ê¸°ì¡´ ëª¨ë“ˆ import
import ai_service
import database as db
import report_generator as rpt

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# Streamlit Secretsì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
try:
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
    DB_URL = st.secrets["DB_URL"]
except KeyError as e:
    st.error(f"ğŸš¨ í™˜ê²½ ë³€ìˆ˜ {e}ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! Streamlit Cloud 'Secrets'ì—ì„œ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ë¡œê·¸
logging.info(f"âœ… OpenAI API Key ë° DB URL ë¡œë“œ ì™„ë£Œ")

# í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ í™•ì¸
REQUIRED_VARS = ["OPENAI_API_KEY", "DB_URL"]
missing = [var for var in REQUIRED_VARS if var not in st.secrets]
if missing:
    st.error(f"ğŸš¨ í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing)}")
    st.stop()

# ìºì‹œëœ DataManager (ì¶”í›„ í™•ì¥ì„ ìœ„í•´ í´ë˜ìŠ¤ë¡œ ê°ìŒ€ ìˆ˜ ìˆìŒ)
# ìºì‹œëœ DataManager (ì¶”í›„ í™•ì¥ì„ ìœ„í•´ í´ë˜ìŠ¤ë¡œ ê°ìŒ€ ìˆ˜ ìˆìŒ)
class DataManager:
    @staticmethod
    def save_dataframe(df: pd.DataFrame, table_name: str) -> bool:
        return db.save_to_postgres(df, table_name)

    @staticmethod
    def fetch_dataframe(table_name: str) -> pd.DataFrame:
        return db.fetch_from_postgres(table_name)
    
    @staticmethod
    def list_tables() -> list:
        return db.list_tables()
    
    @staticmethod
    def save_analysis(file_name: str, sheet_name: str, table_structure: str, analysis_queries: str,
                      insights: str, raw_sample_data: str, ppt_report: str = None) -> bool:
        return db.save_analysis_result(file_name, sheet_name, table_structure, analysis_queries, insights, raw_sample_data, ppt_report)
    
    @staticmethod
    def list_analysis() -> pd.DataFrame:
        return db.list_analysis_results()

# ì„ì‹œ íŒŒì¼ ì •ë¦¬ í•¨ìˆ˜
def cleanup_temp_files(*paths):
    for path in paths:
        if path and os.path.exists(path):
            try:
                os.remove(path)
            except Exception as e:
                logging.error(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì˜¤ë¥˜: {e}")

# í˜ì´ì§€ë³„ í•¨ìˆ˜ ì •ì˜

def upload_and_analyze_page():
    st.title("ğŸ“‚ ë°ì´í„° ì—…ë¡œë“œ ë° AI ë¶„ì„")
    uploaded_file = st.file_uploader("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì—‘ì…€/CSV)", type=["xlsx", "csv"])
    save_archive = st.checkbox("ë¶„ì„ ê²°ê³¼ ìë™ ì•„ì¹´ì´ë¸Œ ì €ì¥", value=True)
    generate_visuals = st.checkbox("ì‹œê°í™” ë° PPT ë³´ê³ ì„œ ìƒì„±", value=False)

    if uploaded_file:
        tmp_path = None
        chart_path = None
        ppt_filename = None
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp:
                tmp.write(uploaded_file.getbuffer())
                tmp_path = tmp.name

            # íŒŒì¼ ì½ê¸° (ì—‘ì…€ ë˜ëŠ” CSV)
            if uploaded_file.name.endswith("xlsx"):
                sheets = pd.read_excel(tmp_path, sheet_name=None)
                if not sheets:
                    st.error("ì—‘ì…€ íŒŒì¼ì— ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return
                sheet_names = list(sheets.keys())
                selected_sheet = st.selectbox("ë¶„ì„í•  ì‹œíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”", sheet_names)
                df = sheets[selected_sheet]
            else:
                df = pd.read_csv(tmp_path)

            st.subheader("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            st.dataframe(df.head())

            # ì»¬ëŸ¼ëª… ì •ë¦¬ (ê¸°ì¡´ ai_service.clean_column_names ì‚¬ìš©) :contentReference[oaicite:6]{index=6}
            df.columns = ai_service.clean_column_names(df.columns)

            # DB ì €ì¥
            table_name = os.path.splitext(uploaded_file.name)[0].replace(" ", "_").lower()
            if DataManager.save_dataframe(df, table_name):
                st.success("âœ… ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.error("ğŸš¨ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨")
                return

            # AI ë¶„ì„: í…Œì´ë¸” êµ¬ì¡°, ë¶„ì„ ì¿¼ë¦¬, ê²½ì˜ ì¸ì‚¬ì´íŠ¸
            columns_info = df.dtypes.to_string()
            table_structure = ai_service.analyze_data_structure(columns_info)
            sample_data = df.head().to_csv(index=False)
            analysis_queries = ai_service.generate_analysis_queries(sample_data)
            insights = ai_service.generate_management_insights(sample_data)

            st.subheader("AIê°€ ìƒì„±í•œ PostgreSQL ì½”ë“œ")
            st.code(table_structure, language="sql")
            st.subheader("AIê°€ ìƒì„±í•œ ë¶„ì„ ì¿¼ë¦¬")
            st.code(analysis_queries, language="sql")
            st.subheader("ê²½ì˜ ì¸ì‚¬ì´íŠ¸")
            st.write(insights)

            # ê²°ê³¼ ì•„ì¹´ì´ë¸Œ ì €ì¥
            if save_archive:
                DataManager.save_analysis(uploaded_file.name, selected_sheet if uploaded_file.name.endswith("xlsx") else table_name,
                                            table_structure, analysis_queries, insights, sample_data)

            # ì¶”ê°€ ì‹œê°í™” ë° PPT ìƒì„±
            if generate_visuals:
                # ê°„ë‹¨í•œ ì°¨íŠ¸ ìƒì„± (ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ìš°ì„  ì„ íƒ)
                numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()
                if numeric_cols:
                    numeric_col = numeric_cols[0]
                else:
                    numeric_col = df.columns[0]
                y_vals = df[numeric_col].dropna().astype(float).head(10).tolist()
                n = len(y_vals)
                chart_data = {"x": list(range(1, n + 1)), "y": y_vals}
                chart_path = rpt.generate_sample_chart(chart_data, title="ìƒ˜í”Œ ì‹œê³„ì—´ ë¶„ì„")
                if chart_path:
                    st.image(chart_path, caption="ë¶„ì„ ì°¨íŠ¸", use_column_width=True)
                    ppt_filename = rpt.create_ppt_report(insights, table_structure, chart_path)
                    if ppt_filename:
                        st.success(f"PPT ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {ppt_filename}")
                        with open(ppt_filename, "rb") as f:
                            st.download_button("PPT ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ", f, file_name=ppt_filename,
                                               mime="application/vnd.openxmlformats-officedocument.presentationml.presentation")
                    else:
                        st.error("PPT ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨")
            else:
                st.info("ì‹œê°í™” ë° PPT ë³´ê³ ì„œ ìƒì„±ì„ ì›í•˜ì‹œë©´ í•´ë‹¹ ì˜µì…˜ì„ ì²´í¬í•˜ì„¸ìš”.")
        except Exception as e:
            st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            logging.error(e)
        finally:
            cleanup_temp_files(tmp_path, chart_path, ppt_filename)

def dashboard_page():
    st.title("ğŸ“Š ë°ì´í„° ëŒ€ì‹œë³´ë“œ")
    tables = DataManager.list_tables()
    if not tables:
        st.info("ì €ì¥ëœ í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    selected_table = st.selectbox("í…Œì´ë¸” ì„ íƒ", tables)
    if st.button("ë°ì´í„° ì¡°íšŒ"):
        df_stored = DataManager.fetch_dataframe(selected_table)
        if df_stored.empty:
            st.info("ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.subheader(f"'{selected_table}' í…Œì´ë¸” ë°ì´í„°")
            st.dataframe(df_stored)
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ", df_stored.to_csv(index=False).encode('utf-8'),
                               file_name=f"{selected_table}.csv", mime="text/csv")
            st.info("PowerBIëŠ” PostgreSQL DB í˜¹ì€ CSV íŒŒì¼ì„ í†µí•´ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

def analysis_archive_page():
    st.title("ğŸ—‚ ë¶„ì„ ê²°ê³¼ ì•„ì¹´ì´ë¸Œ")
    df_archive = DataManager.list_analysis()
    if df_archive.empty:
        st.info("ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.dataframe(df_archive)
        st.info("IDë¥¼ ì„ íƒí•˜ì—¬ ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

def about_page():
    st.title("About")
    st.markdown("""
    ###  AI ê²½ì˜/ì¡°ì§ ì§„ë‹¨ ì»¨ì„¤íŒ… ì‹œìŠ¤í…œ  
    - **ë°ì´í„° ì „ì²˜ë¦¬ ë° DB ì €ì¥**: ì—…ë¡œë“œëœ íŒŒì¼ì„ PostgreSQLì— ì•ˆì „í•˜ê²Œ ì €ì¥í•©ë‹ˆë‹¤.  
    - **AI ë¶„ì„ ì—”ì§„**: OpenAI GPT-4ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ AIê°€ ë°ì´í„° êµ¬ì¡°, ë¶„ì„ ì¿¼ë¦¬ ë° ê²½ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.  
    - **ê³ ê¸‰ ì‹œê°í™” ë° ë³´ê³ ì„œ**: Matplotlibì™€ python-pptxë¥¼ í™œìš©í•´ ê³ í€„ë¦¬í‹° ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.  
    - **PowerBI ì—°ë™**: PostgreSQL DB ë° CSV ë‚´ë³´ë‚´ê¸°ë¥¼ í†µí•´ PowerBIì™€ ì†ì‰½ê²Œ ì—°ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
     
    â€» ì´ ì‹œìŠ¤í…œì€ Docker, CI/CD, ë¡œê¹… ë“± ìš´ì˜í™˜ê²½ì— ë§ì¶° í™•ì¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    """)

# ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜
page_options = {
    "ë°ì´í„° ì—…ë¡œë“œ & ë¶„ì„": upload_and_analyze_page,
    "ëŒ€ì‹œë³´ë“œ": dashboard_page,
    "ë¶„ì„ ê²°ê³¼ ì•„ì¹´ì´ë¸Œ": analysis_archive_page,
    "About": about_page
}

st.sidebar.title("ë©”ë‰´")
selection = st.sidebar.radio("í˜ì´ì§€ ì„ íƒ", list(page_options.keys()))
page_options[selection]()
